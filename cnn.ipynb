{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwvibrwvLzFI"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from glob import glob\n",
        "import seaborn as sns\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from glob import glob\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "np.random.seed(11) # It's my lucky number\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import itertools\n",
        "\n",
        "import keras\n",
        "from keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "Q_-VgoCVR4Uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2zNb90jR5OE",
        "outputId": "bf73bc8f-7e0b-46bf-9339-4ce96ff1e4e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hrj-mVkmVaF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_benign_train = '/content/gdrive/MyDrive/data_rename/train/benign'\n",
        "folder_insitu_train = '/content/gdrive/MyDrive/data_rename/train/insitu'\n",
        "folder_invasive_train = '/content/gdrive/MyDrive/data_rename/train/invasive'\n",
        "folder_later_train = '/content/gdrive/MyDrive/data_rename/train/later'\n",
        "\n",
        "folder_benign_validation = '/content/gdrive/MyDrive/data_rename/test/benign'\n",
        "folder_insitu_validation = '/content/gdrive/MyDrive/data_rename/test/insitu'\n",
        "folder_invasive_validation = '/content/gdrive/MyDrive/data_rename/test/invasive'\n",
        "folder_later_validation = '/content/gdrive/MyDrive/data_rename/test/later'"
      ],
      "metadata": {
        "id": "CnVFx8-rR9B-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path='/content/gdrive/MyDrive/data_rename/train'\n",
        "validation_path='/content/gdrive/MyDrive/data_rename/test'"
      ],
      "metadata": {
        "id": "PkxxJtdjSA6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io"
      ],
      "metadata": {
        "id": "gZLImvr0Wae7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/gdrive/MyDrive/data_rename/train/benign/thumbnail_256(10) (2).jpg'\n",
        "img = io.imread(img_path)\n",
        "img.shape\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "fKGCe02kSElN",
        "outputId": "c9fa2f7c-9414-4f2b-dc24-c54fc56863c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1e5d5309a0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/train/benign'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.resize((224,224))\n",
        "    img.save(f_img)"
      ],
      "metadata": {
        "id": "GrwKjzpvSKbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/train/insitu'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.resize((224,224))\n",
        "    img.save(f_img)"
      ],
      "metadata": {
        "id": "laJAGU9ISO_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/train/invasive'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.resize((224,224))\n",
        "    img.save(f_img)"
      ],
      "metadata": {
        "id": "8EISVNgYSRlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/train/later'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.resize((224,224))\n",
        "    img.save(f_img)"
      ],
      "metadata": {
        "id": "Ojrrrz2KW4iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/test/benign'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.resize((224,224))\n",
        "    img.save(f_img)"
      ],
      "metadata": {
        "id": "QyYiMmsgW5jS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/test/insitu'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.resize((224,224))\n",
        "    img.save(f_img)"
      ],
      "metadata": {
        "id": "MVATioNKW6FH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/test/invasive'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.resize((224,224))\n",
        "    img.save(f_img)"
      ],
      "metadata": {
        "id": "TVMnKUBJW6iW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/test/later'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.resize((224,224))\n",
        "    img.save(f_img)"
      ],
      "metadata": {
        "id": "WfrEBSk-W65d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n",
        "\n",
        "# Load in training pictures\n",
        "ims_benign = [read(os.path.join(folder_benign_train, filename)) for filename in os.listdir(folder_benign_train)]\n",
        "X_benign = np.array((ims_benign), dtype='uint8')\n",
        "ims_insitu = [read(os.path.join(folder_insitu_train, filename)) for filename in os.listdir(folder_insitu_train)]\n",
        "X_insitu = np.array(ims_insitu, dtype='uint8')\n",
        "ims_invasive = [read(os.path.join(folder_invasive_train, filename)) for filename in os.listdir(folder_invasive_train)]\n",
        "X_invasive = np.array(ims_invasive, dtype='uint8')\n",
        "ims_later = [read(os.path.join(folder_later_train, filename)) for filename in os.listdir(folder_later_train)]\n",
        "X_later = np.array(ims_later, dtype='uint8')"
      ],
      "metadata": {
        "id": "cD_nFR-IXU0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dull razor\n"
      ],
      "metadata": {
        "id": "T-3oBDkMXZW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "def dull_razor(data1):\n",
        "\n",
        "\n",
        "    #Image cropping\n",
        "    img=data1[30:410,30:560]\n",
        "    #DULL RAZOR (REMOVE HAIR)\n",
        "\n",
        "    #Gray scale\n",
        "    grayScale = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY )\n",
        "    #Black hat filter\n",
        "    kernel = cv2.getStructuringElement(1,(9,9))\n",
        "    blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n",
        "    #Gaussian filter\n",
        "    #bhg= cv2.GaussianBlur(blackhat,(3,3),cv2.BORDER_DEFAULT)\n",
        "    #Binary thresholding (MASK)\n",
        "    ret,mask = cv2.threshold(blackhat,10,255,cv2.THRESH_BINARY)\n",
        "    #Replace pixels of the mask\n",
        "    dst = cv2.inpaint(img,mask,6,cv2.INPAINT_TELEA)\n",
        "\n",
        "\n",
        "\n",
        "    #plt.figure(figsize=(11,6))\n",
        "    #plt.subplot(141), plt.imshow(image, cmap='gray'),plt.title('Original')\n",
        "    #plt.xticks([]), plt.yticks([])\n",
        "    #plt.subplot(142), plt.imshow(grayScale, cmap='gray'),plt.title('blackhat')\n",
        "    #plt.xticks([]), plt.yticks([])\n",
        "    #plt.subplot(143), plt.imshow(mask, cmap='gray'),plt.title('mask')\n",
        "    #plt.xticks([]), plt.yticks([])\n",
        "    #plt.subplot(144), plt.imshow(dst, cmap='gray'),plt.title('final')\n",
        "    #plt.xticks([]), plt.yticks([])\n",
        "    #plt.show()\n",
        "\n",
        "    return dst\n",
        "\n",
        "#path = '/content/gdrive/My Drive/data/train/malignant_train/000ba687-b41b-43d3-b158-e84c3d538b84.jpg'\n",
        "#image=io.imread(path)\n"
      ],
      "metadata": {
        "id": "_UhdcksrXV6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/test/benign'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = cv2.imread(f_img)\n",
        "    #image2 = cv2.cvtColor(image2, cv2.COLOR_GRAY2BGR)\n",
        "    new = dull_razor(img)\n",
        "    #img = img.filter(ImageFilter.MedianFilter)\n",
        "    cv2.imwrite(f_img,new)"
      ],
      "metadata": {
        "id": "AqpUKFabXjTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/test/insitu'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = cv2.imread(f_img)\n",
        "    #image2 = cv2.cvtColor(image2, cv2.COLOR_GRAY2BGR)\n",
        "    new = dull_razor(img)\n",
        "    #img = img.filter(ImageFilter.MedianFilter)\n",
        "    cv2.imwrite(f_img,new)"
      ],
      "metadata": {
        "id": "ZULDmSavXjyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/test/invasive'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = cv2.imread(f_img)\n",
        "    #image2 = cv2.cvtColor(image2, cv2.COLOR_GRAY2BGR)\n",
        "    new = dull_razor(img)\n",
        "    #img = img.filter(ImageFilter.MedianFilter)\n",
        "    cv2.imwrite(f_img,new)"
      ],
      "metadata": {
        "id": "RQr3L1Q6Xnau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/test/later'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = cv2.imread(f_img)\n",
        "    #image2 = cv2.cvtColor(image2, cv2.COLOR_GRAY2BGR)\n",
        "    new = dull_razor(img)\n",
        "    #img = img.filter(ImageFilter.MedianFilter)\n",
        "    cv2.imwrite(f_img,new)"
      ],
      "metadata": {
        "id": "fdhqM0VPXre4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/train/benign'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = cv2.imread(f_img)\n",
        "    #image2 = cv2.cvtColor(image2, cv2.COLOR_GRAY2BGR)\n",
        "    new = dull_razor(img)\n",
        "    #img = img.filter(ImageFilter.MedianFilter)\n",
        "    cv2.imwrite(f_img,new)"
      ],
      "metadata": {
        "id": "fcTdyGrgXuQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/train/insitu'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = cv2.imread(f_img)\n",
        "    #image2 = cv2.cvtColor(image2, cv2.COLOR_GRAY2BGR)\n",
        "    new = dull_razor(img)\n",
        "    #img = img.filter(ImageFilter.MedianFilter)\n",
        "    cv2.imwrite(f_img,new)"
      ],
      "metadata": {
        "id": "VPVxfB5kYHWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/train/invasive'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = cv2.imread(f_img)\n",
        "    #image2 = cv2.cvtColor(image2, cv2.COLOR_GRAY2BGR)\n",
        "    new = dull_razor(img)\n",
        "    #img = img.filter(ImageFilter.MedianFilter)\n",
        "    cv2.imwrite(f_img,new)"
      ],
      "metadata": {
        "id": "DHZt_S-IYKXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/train/later'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = cv2.imread(f_img)\n",
        "    #image2 = cv2.cvtColor(image2, cv2.COLOR_GRAY2BGR)\n",
        "    new = dull_razor(img)\n",
        "    #img = img.filter(ImageFilter.MedianFilter)\n",
        "    cv2.imwrite(f_img,new)"
      ],
      "metadata": {
        "id": "2_anUTbIYLPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/train/benign'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.filter(ImageFilter.MedianFilter)\n",
        "    img.save(f_img)"
      ],
      "metadata": {
        "id": "cMyUxUf0Ya2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/train/insitu'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.filter(ImageFilter.MedianFilter)\n",
        "    img.save(f_img)"
      ],
      "metadata": {
        "id": "Lh8oEi02Yb6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/train/invasive'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.filter(ImageFilter.MedianFilter)\n",
        "    img.save(f_img)"
      ],
      "metadata": {
        "id": "ZzgeDkb5YctD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/train/later'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.filter(ImageFilter.MedianFilter)\n",
        "    img.save(f_img)"
      ],
      "metadata": {
        "id": "g2DbYayHYdja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/test/benign'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.filter(ImageFilter.MedianFilter)\n",
        "    img.save(f_img)"
      ],
      "metadata": {
        "id": "8D6RQZg0YeT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/test/insitu'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.filter(ImageFilter.MedianFilter)\n",
        "    img.save(f_img)"
      ],
      "metadata": {
        "id": "NhTD876yYe_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/test/invasive'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.filter(ImageFilter.MedianFilter)\n",
        "    img.save(f_img)"
      ],
      "metadata": {
        "id": "Ynu10ECPYfxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "f = r'/content/gdrive/MyDrive/data_rename/test/later'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.filter(ImageFilter.MedianFilter)\n",
        "    img.save(f_img)"
      ],
      "metadata": {
        "id": "9umqQvGzYgd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "import keras\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras_preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "import math\n",
        "import datetime\n",
        "import time"
      ],
      "metadata": {
        "id": "vKxUnkMpZJvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Default dimensions we found online\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "#Create a bottleneck file\n",
        "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
        "# loading up our datasets\n",
        "train_data_dir='/content/gdrive/MyDrive/data_rename/train'\n",
        "validation_data_dir='/content/gdrive/MyDrive/data_rename/test'\n",
        "# number of epochs to train top model\n",
        "epochs = 7 #this has been changed after multiple model run\n",
        "# batch size used by flow_from_directory and predict_generator\n",
        "batch_size = 50"
      ],
      "metadata": {
        "id": "Akk5f7NMZYQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading vgc16 model\n",
        "vgg16=applications.VGG16(include_top=False, weights='imagenet')\n",
        "datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "#needed to create the bottleneck .npy files"
      ],
      "metadata": {
        "id": "B5Oe3mdaZeA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1. / 255)"
      ],
      "metadata": {
        "id": "BUO5Pw0GZhiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train- creation of weights and features using vgg16\n",
        "start = datetime.datetime.now()\n",
        "\n",
        "generator = datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False)\n",
        "\n",
        "nb_train_samples = len(generator.filenames)\n",
        "num_classes = len(generator.class_indices)\n",
        "\n",
        "predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
        "\n",
        "bottleneck_features_train = vgg16.predict_generator(generator, predict_size_train)\n",
        "\n",
        "np.save('bottleneck_features_train.npy', bottleneck_features_train)\n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print('Time: ', elapsed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X9HtVZlZlj4",
        "outputId": "26a78d53-acfc-488b-f82e-91edeb0051ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3360 images belonging to 4 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-c6ab365cfe62>:16: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  bottleneck_features_train = vgg16.predict_generator(generator, predict_size_train)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time:  0:29:57.032529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#validation -creation of weights and features using vgg16\n",
        "start = datetime.datetime.now()\n",
        "\n",
        "generator = datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False)\n",
        "\n",
        "nb_validation_samples = len(generator.filenames)\n",
        "num_classes = len(generator.class_indices)\n",
        "\n",
        "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
        "\n",
        "bottleneck_features_validation = vgg16.predict_generator(generator, predict_size_validation)\n",
        "\n",
        "np.save('bottleneck_features_validation.npy', bottleneck_features_validation)\n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ('Time: ', elapsed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "979yYC4XZoj_",
        "outputId": "6bf21c3b-60f5-4e58-978d-01830abf360f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 450 images belonging to 4 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-1f7c383a8521>:16: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  bottleneck_features_validation = vgg16.predict_generator(generator, predict_size_validation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time:  0:04:22.334846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = datetime.datetime.now()\n",
        "datagen_top = ImageDataGenerator(rescale=1./255)\n",
        "generator_top = datagen_top.flow_from_directory(\n",
        "         train_data_dir,\n",
        "         target_size=(img_width, img_height),\n",
        "         batch_size=batch_size,\n",
        "         class_mode='categorical',\n",
        "         shuffle=False)\n",
        "\n",
        "nb_train_samples = len(generator_top.filenames)\n",
        "num_classes = len(generator_top.class_indices)\n",
        "\n",
        "# load the bottleneck features saved earlier\n",
        "train_data = np.load('bottleneck_features_train.npy')\n",
        "\n",
        "# get the class lebels for the training data, in the original order\n",
        "train_labels = generator_top.classes\n",
        "\n",
        "# convert the training labels to categorical vectors\n",
        "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ('Time: ', elapsed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8QNU6xLZou1",
        "outputId": "8e69e58f-cba5-40d8-a5b5-7a3afad76272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3360 images belonging to 4 classes.\n",
            "Time:  0:00:00.347230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator_top = datagen_top.flow_from_directory(\n",
        "         validation_data_dir,\n",
        "         target_size=(img_width, img_height),\n",
        "         batch_size=batch_size,\n",
        "         class_mode=None,\n",
        "         shuffle=False)\n",
        "\n",
        "nb_validation_samples = len(generator_top.filenames)\n",
        "\n",
        "validation_data = np.load('bottleneck_features_validation.npy')\n",
        "\n",
        "\n",
        "validation_labels = generator_top.classes\n",
        "validation_labels = to_categorical(validation_labels, num_classes=num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoIHdYVvaPL5",
        "outputId": "65bac3e6-df0c-437a-bebf-918d0fa9ab7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 450 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#method1\n",
        "start = datetime.datetime.now()\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "          loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data, train_labels,\n",
        "      epochs=5,\n",
        "      batch_size=batch_size,\n",
        "      validation_data=(validation_data, validation_labels))\n",
        "\n",
        "model.save_weights(top_model_weights_path)\n",
        "\n",
        "(eval_loss, eval_accuracy) = model.evaluate(\n",
        " validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
        "\n",
        "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
        "print(\"[INFO] Loss: {}\".format(eval_loss))\n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ('Time: ', elapsed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYtY1bjBakpW",
        "outputId": "aa70a939-b088-45aa-8cc7-d69e1ffb54ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "68/68 [==============================] - 7s 89ms/step - loss: 2.4117 - accuracy: 0.3628 - val_loss: 1.2039 - val_accuracy: 0.5422\n",
            "Epoch 2/5\n",
            "68/68 [==============================] - 6s 88ms/step - loss: 1.1926 - accuracy: 0.4446 - val_loss: 1.1092 - val_accuracy: 0.5156\n",
            "Epoch 3/5\n",
            "68/68 [==============================] - 6s 88ms/step - loss: 1.0757 - accuracy: 0.5143 - val_loss: 1.0031 - val_accuracy: 0.6089\n",
            "Epoch 4/5\n",
            "68/68 [==============================] - 6s 85ms/step - loss: 0.9918 - accuracy: 0.5467 - val_loss: 0.9415 - val_accuracy: 0.5756\n",
            "Epoch 5/5\n",
            "68/68 [==============================] - 7s 100ms/step - loss: 0.9533 - accuracy: 0.5568 - val_loss: 0.9293 - val_accuracy: 0.5600\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.9293 - accuracy: 0.5600\n",
            "[INFO] accuracy: 56.00%\n",
            "[INFO] Loss: 0.9292657375335693\n",
            "Time:  0:00:42.204806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#method2\n",
        "start = datetime.datetime.now()\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_data, train_labels,\n",
        "      epochs=7,\n",
        "      batch_size=batch_size,\n",
        "      validation_data=(validation_data, validation_labels))\n",
        "\n",
        "model.save_weights(top_model_weights_path)\n",
        "\n",
        "(eval_loss, eval_accuracy) = model.evaluate(\n",
        " validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
        "\n",
        "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
        "print(\"[INFO] Loss: {}\".format(eval_loss))\n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ('Time: ', elapsed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6jn45d0aklw",
        "outputId": "9db13db5-190d-42c5-bb33-1c8e38ac4dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68/68 [==============================] - 4s 44ms/step - loss: 1.3817 - acc: 0.3000 - val_loss: 1.3458 - val_acc: 0.2489\n",
            "Epoch 2/7\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 1.3332 - acc: 0.3524 - val_loss: 1.2914 - val_acc: 0.5578\n",
            "Epoch 3/7\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 1.2766 - acc: 0.4080 - val_loss: 1.2514 - val_acc: 0.5178\n",
            "Epoch 4/7\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 1.2404 - acc: 0.4396 - val_loss: 1.2011 - val_acc: 0.5733\n",
            "Epoch 5/7\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 1.2076 - acc: 0.4524 - val_loss: 1.2301 - val_acc: 0.4933\n",
            "Epoch 6/7\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.1670 - acc: 0.4777 - val_loss: 1.1136 - val_acc: 0.6000\n",
            "Epoch 7/7\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 1.1285 - acc: 0.4917 - val_loss: 1.1029 - val_acc: 0.5844\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.1029 - acc: 0.5844\n",
            "[INFO] accuracy: 58.44%\n",
            "[INFO] Loss: 1.102916955947876\n",
            "Time:  0:00:21.478283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#method3\n",
        "import keras\n",
        "from keras import optimizers\n",
        "start = datetime.datetime.now()\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "model.add(Dense(100, activation=keras.layers.LeakyReLU(alpha=0.3)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(50, activation=keras.layers.LeakyReLU(alpha=0.3)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_data, train_labels,\n",
        "      epochs=7,\n",
        "      batch_size=batch_size,\n",
        "      validation_data=(validation_data, validation_labels))\n",
        "\n",
        "model.save_weights(top_model_weights_path)\n",
        "\n",
        "(eval_loss, eval_accuracy) = model.evaluate(\n",
        " validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
        "\n",
        "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
        "print(\"[INFO] Loss: {}\".format(eval_loss))\n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ('Time: ', elapsed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0itP3n8at9y",
        "outputId": "a6b0ea22-8269-4882-8281-9dacece984e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "68/68 [==============================] - 4s 43ms/step - loss: 1.3309 - acc: 0.3720 - val_loss: 1.1318 - val_acc: 0.4689\n",
            "Epoch 2/7\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.0902 - acc: 0.5250 - val_loss: 1.0867 - val_acc: 0.5333\n",
            "Epoch 3/7\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 0.9788 - acc: 0.5795 - val_loss: 1.0920 - val_acc: 0.5889\n",
            "Epoch 4/7\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.9069 - acc: 0.6104 - val_loss: 0.8729 - val_acc: 0.5933\n",
            "Epoch 5/7\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.8461 - acc: 0.6396 - val_loss: 0.8824 - val_acc: 0.6378\n",
            "Epoch 6/7\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.8059 - acc: 0.6685 - val_loss: 0.9047 - val_acc: 0.5867\n",
            "Epoch 7/7\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.7799 - acc: 0.6604 - val_loss: 0.8065 - val_acc: 0.6467\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.8065 - acc: 0.6467\n",
            "[INFO] accuracy: 64.67%\n",
            "[INFO] Loss: 0.8064914345741272\n",
            "Time:  0:00:21.147393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#method4\n",
        "start = datetime.datetime.now()\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "          loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data, train_labels,\n",
        "      epochs=20,\n",
        "      batch_size=batch_size,\n",
        "      validation_data=(validation_data, validation_labels))\n",
        "\n",
        "model.save_weights(top_model_weights_path)\n",
        "\n",
        "(eval_loss, eval_accuracy) = model.evaluate(\n",
        " validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
        "\n",
        "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
        "print(\"[INFO] Loss: {}\".format(eval_loss))\n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ('Time: ', elapsed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YyDGmXVaxjj",
        "outputId": "cb90d90c-dfdb-4132-8fe8-2b672f85b0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "68/68 [==============================] - 6s 72ms/step - loss: 1.7028 - accuracy: 0.2557 - val_loss: 1.3812 - val_accuracy: 0.2844\n",
            "Epoch 2/20\n",
            "68/68 [==============================] - 5s 71ms/step - loss: 1.3700 - accuracy: 0.2973 - val_loss: 1.2860 - val_accuracy: 0.2822\n",
            "Epoch 3/20\n",
            "68/68 [==============================] - 7s 102ms/step - loss: 1.3361 - accuracy: 0.3098 - val_loss: 1.3453 - val_accuracy: 0.3311\n",
            "Epoch 4/20\n",
            "68/68 [==============================] - 6s 86ms/step - loss: 1.3113 - accuracy: 0.3372 - val_loss: 1.2100 - val_accuracy: 0.4667\n",
            "Epoch 5/20\n",
            "68/68 [==============================] - 6s 87ms/step - loss: 1.2975 - accuracy: 0.3455 - val_loss: 1.1741 - val_accuracy: 0.4711\n",
            "Epoch 6/20\n",
            "68/68 [==============================] - 7s 104ms/step - loss: 1.2841 - accuracy: 0.3565 - val_loss: 1.1585 - val_accuracy: 0.4978\n",
            "Epoch 7/20\n",
            "68/68 [==============================] - 8s 114ms/step - loss: 1.2764 - accuracy: 0.3562 - val_loss: 1.1581 - val_accuracy: 0.4556\n",
            "Epoch 8/20\n",
            "68/68 [==============================] - 6s 93ms/step - loss: 1.2647 - accuracy: 0.3619 - val_loss: 1.1702 - val_accuracy: 0.4756\n",
            "Epoch 9/20\n",
            "68/68 [==============================] - 5s 71ms/step - loss: 1.2775 - accuracy: 0.3545 - val_loss: 1.2515 - val_accuracy: 0.3933\n",
            "Epoch 10/20\n",
            "68/68 [==============================] - 7s 99ms/step - loss: 1.2619 - accuracy: 0.3673 - val_loss: 1.1170 - val_accuracy: 0.5400\n",
            "Epoch 11/20\n",
            "68/68 [==============================] - 6s 93ms/step - loss: 1.2589 - accuracy: 0.3658 - val_loss: 1.1226 - val_accuracy: 0.5311\n",
            "Epoch 12/20\n",
            "68/68 [==============================] - 7s 107ms/step - loss: 1.2580 - accuracy: 0.3628 - val_loss: 1.2487 - val_accuracy: 0.3333\n",
            "Epoch 13/20\n",
            "68/68 [==============================] - 8s 124ms/step - loss: 1.2624 - accuracy: 0.3583 - val_loss: 1.1328 - val_accuracy: 0.4889\n",
            "Epoch 14/20\n",
            "68/68 [==============================] - 9s 125ms/step - loss: 1.2515 - accuracy: 0.3711 - val_loss: 1.3914 - val_accuracy: 0.3911\n",
            "Epoch 15/20\n",
            "68/68 [==============================] - 8s 123ms/step - loss: 1.2499 - accuracy: 0.3780 - val_loss: 1.1751 - val_accuracy: 0.3933\n",
            "Epoch 16/20\n",
            "68/68 [==============================] - 5s 73ms/step - loss: 1.2454 - accuracy: 0.3747 - val_loss: 1.1720 - val_accuracy: 0.4067\n",
            "Epoch 17/20\n",
            "68/68 [==============================] - 5s 72ms/step - loss: 1.2503 - accuracy: 0.3789 - val_loss: 1.1954 - val_accuracy: 0.3556\n",
            "Epoch 18/20\n",
            "68/68 [==============================] - 5s 70ms/step - loss: 1.2541 - accuracy: 0.3670 - val_loss: 1.3051 - val_accuracy: 0.3711\n",
            "Epoch 19/20\n",
            "68/68 [==============================] - 5s 71ms/step - loss: 1.2393 - accuracy: 0.3753 - val_loss: 1.1518 - val_accuracy: 0.3956\n",
            "Epoch 20/20\n",
            "68/68 [==============================] - 5s 70ms/step - loss: 1.2398 - accuracy: 0.3759 - val_loss: 1.2076 - val_accuracy: 0.3533\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 1.2076 - accuracy: 0.3533\n",
            "[INFO] accuracy: 35.33%\n",
            "[INFO] Loss: 1.2075711488723755\n",
            "Time:  0:02:05.456315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image(file_path):\n",
        "    print(\"[INFO] loading and preprocessing image...\")\n",
        "    image = load_img(file_path, target_size=(224, 224))\n",
        "    image = img_to_array(image)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    image /= 255.\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "uWwHjk6-pU7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_single_image(path):\n",
        "    skin = ['benign', '', 'insitu', 'invasive', 'later']\n",
        "    images = read_image(path)\n",
        "    time.sleep(.5)\n",
        "\n",
        "predict_prob=model.predict([testa,testb])\n",
        "\n",
        "predict_classes=np.argmax(predict_prob,axis=1)\n",
        "for idx, skin, x in zip(range(0,6), skin , preds[0]):\n",
        "  print(\"ID: {}, Label: {} {}%\".format(idx, skin, round(x*100,2) ))\n",
        "  print('Final Decision:')\n",
        "  time.sleep(.5)\n",
        "  for x in range(3):\n",
        "    print('.'*(x+1))\n",
        "  time.sleep(.2)\n",
        "  class_predicted = model.predict_classes(bt_prediction)\n",
        "  class_dictionary = generator_top.class_indices\n",
        "  inv_map = {v: k for k, v in class_dictionary.items()}\n",
        "  print(\"ID: {}, Label: {}\".format(class_predicted[0], inv_map[class_predicted[0]]))\n",
        "return load_img(path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "SSMrMW7QpWFG",
        "outputId": "a746f55a-9617-4cbf-b525-9fa429628b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-4a79b624629f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpredict_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtesta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpredict_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_prob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'testa' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "path = '/content/gdrive/MyDrive/data_rename/test/later/0c614c25-4068-4947-abaf-6840d2517e5c (2).jpg'"
      ],
      "metadata": {
        "id": "x1GN7kPbpw_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_single_image(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "gdNjilhep6DA",
        "outputId": "39857b7e-a5c0-446f-969f-dae842a038e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading and preprocessing image...\n",
            "1/1 [==============================] - 1s 555ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-df6415bce9b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_single_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-f15159be21f9>\u001b[0m in \u001b[0;36mtest_single_image\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbt_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbt_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskin\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ID: {}, Label: {} {}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_proba'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/content/gdrive/MyDrive/data_rename/test/later/0c614c25-4068-4947-abaf-6840d2517e5c (2).jpg'\n",
        "\n",
        "orig = mpimg.imread(image_path)\n",
        "\n",
        "print(\"[INFO] Image Loaded\")\n",
        "image = load_img(image_path, target_size=(224, 224))\n",
        "image = img_to_array(image)\n",
        "\n",
        "# important! otherwise the predictions will be '0'\n",
        "image = image / 255\n",
        "\n",
        "image = np.expand_dims(image, axis=0)\n",
        "# print(image)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq8EP94grLcF",
        "outputId": "86a69fa5-a9ab-4ade-ef3b-f28801840d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Image Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tA3e5MXFttXM",
        "outputId": "35ed92cb-b9e8-4026-cc5f-8dcdbe7884d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     || 588.3 MB 18 kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.28.0)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     || 6.0 MB 23.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (14.0.6)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     || 1.7 MB 28.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     || 439 kB 19.4 MB/s \n",
            "\u001b[?25hCollecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.1.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-22.12.6 keras-2.11.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-estimator-2.11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "flatbuffers",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_layer0(filename, batch_input_shape, dtype):\n",
        "    with h5py.File(filename, 'r+') as f:\n",
        "        model_config = json.loads(f.attrs['model_config'].decode('utf-8'))\n",
        "        layer0 = model_config['config']['layers'][0]['config']\n",
        "        layer0['batch_input_shape'] = batch_input_shape\n",
        "        layer0['dtype'] = dtype\n",
        "        f.attrs['model_config'] = json.dumps(model_config).encode('utf-8')\n",
        "\n",
        "fix_layer0('model.h5', [None, 224, 224, 3], 'float32')\n",
        "\n",
        "loaded_model = load_model('model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "7uaJI4bHuS6B",
        "outputId": "294ab66e-8f74-495f-d161-3813132bb83f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-fadce09ed696>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfix_layer0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-77-fadce09ed696>\u001b[0m in \u001b[0;36mfix_layer0\u001b[0;34m(filename, batch_input_shape, dtype)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfix_layer0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_input_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mlayer0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mlayer0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_input_shape'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_input_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'h5py' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the VGG16 network\n",
        "model = applications.VGG16(include_top=False, weights='imagenet')\n",
        "\n",
        "# get the bottleneck prediction from the pre-trained VGG16 model\n",
        "bottleneck_prediction = model.predict(image)\n",
        "\n",
        "# build top model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=bottleneck_prediction.shape[1:]))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.load_weights(top_model_weights_path)\n",
        "\n",
        "# use the bottleneck prediction on the top model to get the final classification\n",
        "class_predicted = model.predict_classes(bottleneck_prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "9ipbO-aqrWWE",
        "outputId": "a785ffdc-ba94-4d2d-bde5-ebf6f46d3e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-096dc578d0cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_model_weights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# use the bottleneck prediction on the top model to get the final classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, model)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Layer count mismatch when loading weights from file. Model expected 3 layers, found 4 saved layers."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inID = class_predicted[0]\n",
        "\n",
        "class_dictionary = generator_top.class_indices\n",
        "\n",
        "inv_map = {v: k for k, v in class_dictionary.items()}\n",
        "\n",
        "label = inv_map[inID]\n",
        "\n",
        "# get the prediction label\n",
        "print(\"Image ID: {}, Label: {}\".format(inID, label))\n",
        "\n",
        "# # display the predictions with the image\n",
        "# cv2.putText(orig, \"Predicted: {}\".format(label), (10, 30), cv2.FONT_HERSHEY_PLAIN, 1.5, (43, 99, 255), 2)\n",
        "\n",
        "# cv2.imshow(\"Classification\", orig)\n",
        "# cv2.waitKey(0)\n",
        "# cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Be4LzUSusIQ8",
        "outputId": "97166748-8fe4-4d42-bb92-77495709a2d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-0b7bbf583bf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_predicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclass_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_top\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minv_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclass_dictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'class_predicted' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "# img = np.random.rand(224,224,3)\n",
        "# plt.imshow(img)\n",
        "# plt.show()\n",
        "\n",
        "img_path = image_path\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "print(type(img))\n",
        "\n",
        "x = image.img_to_array(img)\n",
        "print(type(x))\n",
        "print(x.shape)\n",
        "plt.imshow(x/255.)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "iupyzwb9sI4A",
        "outputId": "7c93a9a1-ad57-41c8-bdc5-d8143716576a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-1bcdfc3448d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras.preprocessing.image' has no attribute 'load_img'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload flower jpeg file from local computer\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "2g5goMbZwyy2",
        "outputId": "6515a99e-fca1-403b-f853-698fc87bccdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-10e33132-8fcf-42c1-bb9d-8f7589bc6ab1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-10e33132-8fcf-42c1-bb9d-8f7589bc6ab1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving thumbnail_256(224).jpg to thumbnail_256(224).jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YyvddQunzMV9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}