{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWusX4_CZ6NY",
        "outputId": "1616baaa-d6fa-43c9-bf26-c137d3ea90dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "import keras\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras_preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "import math\n",
        "import datetime\n",
        "import time"
      ],
      "metadata": {
        "id": "8HrsP74gaBy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "#Create a bottleneck file\n",
        "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
        "# loading up our datasets\n",
        "train_data_dir='/content/drive/MyDrive/data_rename/train'\n",
        "validation_data_dir='/content/drive/MyDrive/data_rename/test'\n",
        "# number of epochs to train top model\n",
        "epochs = 7 #this has been changed after multiple model run\n",
        "# batch size used by flow_from_directory and predict_generator\n",
        "batch_size = 50"
      ],
      "metadata": {
        "id": "6XcLyF6kaP24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading vgc16 model\n",
        "vgg16=applications.VGG16(include_top=False, weights='imagenet')\n",
        "datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "#needed to create the bottleneck .npy files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XiNvdR3aSPz",
        "outputId": "927c97a1-a71d-40e3-b237-f143b8729dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1. / 255)"
      ],
      "metadata": {
        "id": "hnxXi5qTaWK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train- creation of weights and features using vgg16\n",
        "start = datetime.datetime.now()\n",
        "\n",
        "generator = datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False)\n",
        "\n",
        "nb_train_samples = len(generator.filenames)\n",
        "num_classes = len(generator.class_indices)\n",
        "\n",
        "predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
        "\n",
        "bottleneck_features_train = vgg16.predict_generator(generator, predict_size_train)\n",
        "\n",
        "np.save('bottleneck_features_train.npy', bottleneck_features_train)\n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print('Time: ', elapsed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYzfwrJEacmT",
        "outputId": "d969f598-5e2b-4963-ba94-7dc957351a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3360 images belonging to 4 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-c6ab365cfe62>:16: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  bottleneck_features_train = vgg16.predict_generator(generator, predict_size_train)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time:  0:29:25.919700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#validation -creation of weights and features using vgg16\n",
        "start = datetime.datetime.now()\n",
        "\n",
        "generator = datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False)\n",
        "\n",
        "nb_validation_samples = len(generator.filenames)\n",
        "num_classes = len(generator.class_indices)\n",
        "\n",
        "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
        "\n",
        "bottleneck_features_validation = vgg16.predict_generator(generator, predict_size_validation)\n",
        "\n",
        "np.save('bottleneck_features_validation.npy', bottleneck_features_validation)\n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ('Time: ', elapsed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qalo26laddU",
        "outputId": "250505d3-3f5d-4074-b470-f11e352272a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 450 images belonging to 4 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-1f7c383a8521>:16: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  bottleneck_features_validation = vgg16.predict_generator(generator, predict_size_validation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time:  0:04:24.799303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = datetime.datetime.now()\n",
        "datagen_top = ImageDataGenerator(rescale=1./255)\n",
        "generator_top = datagen_top.flow_from_directory(\n",
        "         train_data_dir,\n",
        "         target_size=(img_width, img_height),\n",
        "         batch_size=batch_size,\n",
        "         class_mode='categorical',\n",
        "         shuffle=False)\n",
        "\n",
        "nb_train_samples = len(generator_top.filenames)\n",
        "num_classes = len(generator_top.class_indices)\n",
        "\n",
        "# load the bottleneck features saved earlier\n",
        "train_data = np.load('bottleneck_features_train.npy')\n",
        "\n",
        "# get the class lebels for the training data, in the original order\n",
        "train_labels = generator_top.classes\n",
        "\n",
        "# convert the training labels to categorical vectors\n",
        "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ('Time: ', elapsed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Fxa5TxHamfE",
        "outputId": "9177eaa3-3bd3-4dd8-ddb6-a82df212d01d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3360 images belonging to 4 classes.\n",
            "Time:  0:00:01.020797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator_top = datagen_top.flow_from_directory(\n",
        "         validation_data_dir,\n",
        "         target_size=(img_width, img_height),\n",
        "         batch_size=batch_size,\n",
        "         class_mode=None,\n",
        "         shuffle=False)\n",
        "\n",
        "nb_validation_samples = len(generator_top.filenames)\n",
        "\n",
        "validation_data = np.load('bottleneck_features_validation.npy')\n",
        "\n",
        "\n",
        "validation_labels = generator_top.classes\n",
        "validation_labels = to_categorical(validation_labels, num_classes=num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqoqw7ALanTw",
        "outputId": "087bc30a-6ecf-461a-8765-9f5f8ca7a1c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 450 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = datetime.datetime.now()\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "          loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data, train_labels,\n",
        "      epochs=5,\n",
        "      batch_size=batch_size,\n",
        "      validation_data=(validation_data, validation_labels))\n",
        "\n",
        "model.save_weights(top_model_weights_path)\n",
        "\n",
        "(eval_loss, eval_accuracy) = model.evaluate(\n",
        " validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
        "\n",
        "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
        "print(\"[INFO] Loss: {}\".format(eval_loss))\n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ('Time: ', elapsed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3UuzRahuxbQ",
        "outputId": "ae59394a-e8df-43f2-e80b-41d1a708f6b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "68/68 [==============================] - 9s 119ms/step - loss: 2.0043 - accuracy: 0.4089 - val_loss: 1.2295 - val_accuracy: 0.3756\n",
            "Epoch 2/5\n",
            "68/68 [==============================] - 5s 78ms/step - loss: 1.0953 - accuracy: 0.5110 - val_loss: 1.0319 - val_accuracy: 0.5667\n",
            "Epoch 3/5\n",
            "68/68 [==============================] - 6s 94ms/step - loss: 0.9915 - accuracy: 0.5702 - val_loss: 0.9246 - val_accuracy: 0.5600\n",
            "Epoch 4/5\n",
            "68/68 [==============================] - 7s 105ms/step - loss: 0.9171 - accuracy: 0.6080 - val_loss: 1.2768 - val_accuracy: 0.3422\n",
            "Epoch 5/5\n",
            "68/68 [==============================] - 5s 79ms/step - loss: 0.8534 - accuracy: 0.6298 - val_loss: 0.9871 - val_accuracy: 0.5578\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 0.9871 - accuracy: 0.5578\n",
            "[INFO] accuracy: 55.78%\n",
            "[INFO] Loss: 0.9870734810829163\n",
            "Time:  0:00:33.977915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = datetime.datetime.now()\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_data, train_labels,\n",
        "      epochs=7,\n",
        "      batch_size=batch_size,\n",
        "      validation_data=(validation_data, validation_labels))\n",
        "\n",
        "model.save_weights(top_model_weights_path)\n",
        "\n",
        "(eval_loss, eval_accuracy) = model.evaluate(\n",
        " validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
        "\n",
        "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
        "print(\"[INFO] Loss: {}\".format(eval_loss))\n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ('Time: ', elapsed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xF_twNfYu3P4",
        "outputId": "6be6438b-a21d-45e4-f66c-3146a3d31dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68/68 [==============================] - 3s 41ms/step - loss: 1.3496 - acc: 0.3426 - val_loss: 1.2791 - val_acc: 0.4111\n",
            "Epoch 2/7\n",
            "68/68 [==============================] - 3s 39ms/step - loss: 1.2365 - acc: 0.4378 - val_loss: 1.2076 - val_acc: 0.5000\n",
            "Epoch 3/7\n",
            "68/68 [==============================] - 3s 38ms/step - loss: 1.1682 - acc: 0.4786 - val_loss: 1.1188 - val_acc: 0.5289\n",
            "Epoch 4/7\n",
            "68/68 [==============================] - 3s 39ms/step - loss: 1.1162 - acc: 0.5170 - val_loss: 1.0810 - val_acc: 0.5267\n",
            "Epoch 5/7\n",
            "68/68 [==============================] - 3s 38ms/step - loss: 1.0756 - acc: 0.5271 - val_loss: 1.0410 - val_acc: 0.5933\n",
            "Epoch 6/7\n",
            "68/68 [==============================] - 4s 53ms/step - loss: 1.0097 - acc: 0.5839 - val_loss: 1.0222 - val_acc: 0.5356\n",
            "Epoch 7/7\n",
            "68/68 [==============================] - 4s 63ms/step - loss: 0.9842 - acc: 0.5821 - val_loss: 0.9797 - val_acc: 0.5511\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.9797 - acc: 0.5511\n",
            "[INFO] accuracy: 55.11%\n",
            "[INFO] Loss: 0.9796505570411682\n",
            "Time:  0:00:41.874724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#method3\n",
        "import keras\n",
        "from keras import optimizers\n",
        "start = datetime.datetime.now()\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "model.add(Dense(100, activation=keras.layers.LeakyReLU(alpha=0.3)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(50, activation=keras.layers.LeakyReLU(alpha=0.3)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_data, train_labels,\n",
        "      epochs=7,\n",
        "      batch_size=batch_size,\n",
        "      validation_data=(validation_data, validation_labels))\n",
        "\n",
        "model.save_weights(top_model_weights_path)\n",
        "\n",
        "(eval_loss, eval_accuracy) = model.evaluate(\n",
        " validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
        "\n",
        "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
        "print(\"[INFO] Loss: {}\".format(eval_loss))\n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ('Time: ', elapsed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9e_Raa5vA8W",
        "outputId": "b74a8dfa-d5b4-417d-f5e1-c800fcc6e8e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.2875 - acc: 0.4176 - val_loss: 1.2389 - val_acc: 0.4244\n",
            "Epoch 2/7\n",
            "68/68 [==============================] - 3s 39ms/step - loss: 1.0385 - acc: 0.5524 - val_loss: 1.0813 - val_acc: 0.5067\n",
            "Epoch 3/7\n",
            "68/68 [==============================] - 3s 39ms/step - loss: 0.9370 - acc: 0.5973 - val_loss: 1.0000 - val_acc: 0.5644\n",
            "Epoch 4/7\n",
            "68/68 [==============================] - 4s 54ms/step - loss: 0.8607 - acc: 0.6280 - val_loss: 0.9985 - val_acc: 0.5644\n",
            "Epoch 5/7\n",
            "68/68 [==============================] - 4s 54ms/step - loss: 0.8079 - acc: 0.6685 - val_loss: 0.8854 - val_acc: 0.5889\n",
            "Epoch 6/7\n",
            "68/68 [==============================] - 3s 40ms/step - loss: 0.7880 - acc: 0.6687 - val_loss: 0.8970 - val_acc: 0.6156\n",
            "Epoch 7/7\n",
            "68/68 [==============================] - 3s 39ms/step - loss: 0.7494 - acc: 0.6771 - val_loss: 0.9049 - val_acc: 0.6089\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.9049 - acc: 0.6089\n",
            "[INFO] accuracy: 60.89%\n",
            "[INFO] Loss: 0.9048681855201721\n",
            "Time:  0:00:21.805951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#method4\n",
        "start = datetime.datetime.now()\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "          loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data, train_labels,\n",
        "      epochs=20,\n",
        "      batch_size=batch_size,\n",
        "      validation_data=(validation_data, validation_labels))\n",
        "\n",
        "model.save_weights(top_model_weights_path)\n",
        "\n",
        "(eval_loss, eval_accuracy) = model.evaluate(\n",
        " validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
        "\n",
        "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
        "print(\"[INFO] Loss: {}\".format(eval_loss))\n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ('Time: ', elapsed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWwK1xaTvG8j",
        "outputId": "93c7c846-2e3c-402b-bebd-7136168199b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "68/68 [==============================] - 6s 79ms/step - loss: 1.5940 - accuracy: 0.2789 - val_loss: 1.3549 - val_accuracy: 0.3356\n",
            "Epoch 2/20\n",
            "68/68 [==============================] - 5s 68ms/step - loss: 1.3882 - accuracy: 0.2887 - val_loss: 1.3396 - val_accuracy: 0.2533\n",
            "Epoch 3/20\n",
            "68/68 [==============================] - 5s 69ms/step - loss: 1.3532 - accuracy: 0.3423 - val_loss: 1.2881 - val_accuracy: 0.3200\n",
            "Epoch 4/20\n",
            "68/68 [==============================] - 5s 77ms/step - loss: 1.2978 - accuracy: 0.3988 - val_loss: 1.1986 - val_accuracy: 0.5289\n",
            "Epoch 5/20\n",
            "68/68 [==============================] - 6s 82ms/step - loss: 1.2299 - accuracy: 0.4455 - val_loss: 1.1619 - val_accuracy: 0.5489\n",
            "Epoch 6/20\n",
            "68/68 [==============================] - 5s 78ms/step - loss: 1.1870 - accuracy: 0.4685 - val_loss: 1.3857 - val_accuracy: 0.3267\n",
            "Epoch 7/20\n",
            "68/68 [==============================] - 5s 70ms/step - loss: 1.1587 - accuracy: 0.4771 - val_loss: 1.0372 - val_accuracy: 0.5844\n",
            "Epoch 8/20\n",
            "68/68 [==============================] - 5s 70ms/step - loss: 1.1345 - accuracy: 0.4875 - val_loss: 1.1345 - val_accuracy: 0.5422\n",
            "Epoch 9/20\n",
            "68/68 [==============================] - 5s 69ms/step - loss: 1.1220 - accuracy: 0.4896 - val_loss: 1.1688 - val_accuracy: 0.4400\n",
            "Epoch 10/20\n",
            "68/68 [==============================] - 5s 70ms/step - loss: 1.1125 - accuracy: 0.4940 - val_loss: 1.1137 - val_accuracy: 0.4689\n",
            "Epoch 11/20\n",
            "68/68 [==============================] - 5s 69ms/step - loss: 1.0715 - accuracy: 0.5211 - val_loss: 0.9534 - val_accuracy: 0.6200\n",
            "Epoch 12/20\n",
            "68/68 [==============================] - 5s 70ms/step - loss: 1.0704 - accuracy: 0.5226 - val_loss: 0.9767 - val_accuracy: 0.5867\n",
            "Epoch 13/20\n",
            "68/68 [==============================] - 5s 70ms/step - loss: 1.0691 - accuracy: 0.5205 - val_loss: 0.8720 - val_accuracy: 0.6511\n",
            "Epoch 14/20\n",
            "68/68 [==============================] - 5s 70ms/step - loss: 1.0699 - accuracy: 0.5241 - val_loss: 0.9081 - val_accuracy: 0.6533\n",
            "Epoch 15/20\n",
            "68/68 [==============================] - 5s 69ms/step - loss: 1.0663 - accuracy: 0.5241 - val_loss: 0.8485 - val_accuracy: 0.6800\n",
            "Epoch 16/20\n",
            "68/68 [==============================] - 5s 70ms/step - loss: 1.0345 - accuracy: 0.5488 - val_loss: 1.2234 - val_accuracy: 0.4444\n",
            "Epoch 17/20\n",
            "68/68 [==============================] - 5s 69ms/step - loss: 1.0543 - accuracy: 0.5354 - val_loss: 0.8833 - val_accuracy: 0.6489\n",
            "Epoch 18/20\n",
            "68/68 [==============================] - 5s 69ms/step - loss: 1.0520 - accuracy: 0.5292 - val_loss: 0.8605 - val_accuracy: 0.6667\n",
            "Epoch 19/20\n",
            "67/68 [============================>.] - ETA: 0s - loss: 1.0340 - accuracy: 0.5490"
          ]
        }
      ]
    }
  ]
}